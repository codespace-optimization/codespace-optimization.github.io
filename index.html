<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Scattered Forest Search: Smarter Code Space Exploration</title>
  <link rel="stylesheet" href="styles.css" />
</head>
<body>

  <!-- HEADER / TITLE SECTION -->
  <header>
    <h1>Scattered Forest Search</h1>
    <h2>Smarter Code Space Exploration with Scaling LLM Inference</h2>
    <p><strong>Authors:</strong> Jonathan Light, Yue Wu, Yiyou Sun, Wenchao Yu, Yanchi Liu, 
       Xujiang Zhao, Ziniu Hu, Haifeng Chen, Wei Cheng</p>
    <p><em>ICML 2025 (Forthcoming)</em></p>
  </header>

  <!-- LINKS TO PDF, ARXIV, CODE, VIDEO -->
  <section id="links">
    <h3>Links</h3>
    <ul>
      <li><a href="https://arxiv.org/pdf/2411.05010" target="_blank">PDF</a></li>
      <li><a href="https://arxiv.org/abs/2411.05010" target="_blank">Arxiv</a></li>
      <li><a href="https://github.com/codespace-optimization/sfs" target="_blank">Code</a></li>
      <li><a href="https://www.youtube.com/watch?v=Qz6NFMv3ug0" target="_blank">Video</a></li>
    </ul>
  </section>

  <!-- ABSTRACT -->
  <section id="abstract">
    <h3>Abstract</h3>
    <p>
      We propose a novel approach to scaling LLM inference for code generation by
      framing the task as a black-box optimization problem within the code space. Drawing
      on optimization theory, we introduce <strong>Scattered Forest Search (SFS)</strong> to encourage
      both broad exploration of diverse solutions and efficient exploitation of feedback.
      Our method consists of three main components: <em>Scattering</em>, which promotes
      diversity through textual "improvement directions"; <em>Foresting</em>, which extends
      tree search from multiple “seed” solutions; and <em>Scouting</em>, which shares successful
      directions across branches. Empirically, SFS significantly outperforms best-of-N sampling,
      line search, and tree search on standard code-generation benchmarks, achieving higher
      pass rates with fewer LLM calls.
    </p>
  </section>

  <!-- FIGURES / IMAGES -->
  <section id="figures">
    <h3>Figures & Diagrams</h3>

    <!-- Example figure showing confusion matrix -->
    <figure>
      <img src="static/images/confusion.png" alt="Confusion Matrix" style="max-width:400px;">
      <figcaption>Confusion matrix for self-generated validation tests used within SFS.</figcaption>
    </figure>

    <!-- Example figure showing scaling ground truth data -->
    <figure>
      <img src="static/images/scaling_groundtruth.pdf" alt="Scaling Ground Truth" style="max-width:400px;">
      <figcaption>Illustration of how correct solutions scale with repeated generation under SFS.</figcaption>
    </figure>

    <!-- Additional images from your list -->
    <figure>
      <img src="static/images/scaling_high.pdf" alt="High-Level Scaling Overview" style="max-width:400px;">
      <figcaption>A broader look at how SFS consistently outperforms baseline methods as the number of solutions increases.</figcaption>
    </figure>

    <figure>
      <img src="static/images/scaling_model.pdf" alt="Scaling with Different LLMs" style="max-width:400px;">
      <figcaption>Performance trends showing how SFS benefits small vs. large language models.</figcaption>
    </figure>

    <figure>
      <img src="static/images/theme_passk.pdf" alt="Theme-based Prompts" style="max-width:400px;">
      <figcaption>Experiment on diversity: different "themes" in prompts yield improved exploration.</figcaption>
    </figure>

    <figure>
      <img src="static/images/token_scaling.pdf" alt="Token-based Scaling" style="max-width:400px;">
      <figcaption>Comparison of solution discovery vs. tokens consumed for multiple methods.</figcaption>
    </figure>
  </section>

  <!-- VIDEO DEMO -->
  <section id="video-demo">
    <h3>Video Demo</h3>
    <video width="640" height="360" controls>
      <source src="static/videos/sfs_app_demo.mov" type="video/mp4">
      Your browser does not support the video tag.
    </video>
    <p>
      Or watch on YouTube: 
      <a href="https://www.youtube.com/watch?v=Qz6NFMv3ug0" target="_blank">SFS Demo</a>
    </p>
  </section>

  <!-- TECHNICAL OVERVIEW -->
  <section id="technical-overview">
    <h3>Technical Overview</h3>
    <p>
      <strong>Scattering:</strong> The paper introduces a mechanism to prompt the model for 
      “improvement directions” before generating child solutions. Each child solution 
      implements a different textual direction, ensuring greater coverage of code space.
    </p>
    <p>
      <strong>Foresting:</strong> Instead of refining a single seed, the search maintains 
      multiple seed solutions, dynamically deciding which one to improve (via MCTS) and 
      avoiding overcommitment to potentially flawed initial code.
    </p>
    <p>
      <strong>Scouting:</strong> Insights—such as successful or unsuccessful “directions”—are 
      shared across different branches so that good ideas can be reused, improving 
      exploitation of promising search regions.
    </p>
    <p>
      Empirically, SFS enhances both <em>exploration</em> (diverse solutions) and 
      <em>exploitation</em> (iterative refinement), resulting in higher pass@k rates on 
      HumanEval, MBPP, APPS, CodeContests, and Leetcode.
    </p>
  </section>

  <!-- RESULTS SECTION -->
  <section id="results">
    <h3>Key Results</h3>
    <ul>
      <li><strong>Higher pass@k:</strong> SFS outperforms repeated sampling, line search, 
          and naive tree search across code benchmarks.</li>
      <li><strong>Faster discovery:</strong> It finds correct solutions in fewer solution 
          attempts, reducing total LLM calls.</li>
      <li><strong>Better scaling:</strong> SFS continues to improve performance beyond 
          typical plateaus observed in baseline methods, highlighting the role of 
          better exploration.</li>
      <li><strong>Theoretical basis:</strong> The paper offers a Markov chain argument, 
          noting that SCATTERING improves conductance and mixing, helping to escape 
          local maxima in code space.</li>
    </ul>
  </section>

  <!-- CONCLUSION OR NEXT STEPS -->
  <section id="conclusion">
    <h3>Conclusion</h3>
    <p>
      By reframing code generation as a black-box optimization problem, 
      <strong>Scattered Forest Search</strong> systematically exploits iterative feedback 
      while diversifying candidate solutions. The authors demonstrate significant gains 
      in correctness and efficiency on standard code-generation tasks, hinting that 
      such optimization-informed strategies could be broadly useful wherever 
      multiple calls to an LLM are feasible. 
    </p>
  </section>

  <!-- FOOTER -->
  <footer>
    <p>© 2025 SFS Authors – For inquiries, please contact the corresponding author 
       <em>Wei Cheng</em> at NEC Laboratories America.</p>
  </footer>

</body>
</html>
